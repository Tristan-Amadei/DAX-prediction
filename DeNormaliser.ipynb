{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51731b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.2.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as goa\n",
    "import warnings\n",
    "from tbats import TBATS\n",
    "import os\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c98cbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame = pd.read_table(r\"./Data/DailyData_VolumeProfile.csv\", sep = \";\", engine = 'python')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61882d91",
   "metadata": {},
   "source": [
    "## De-normaliser - Moyenne Mobile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac36a252",
   "metadata": {},
   "source": [
    "#### Liste de DataFrames par semaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e02a229",
   "metadata": {},
   "outputs": [],
   "source": [
    "week_days = [\"Lundi\", \"Mardi\", \"Mercredi\", \"Jeudi\", \"Vendredi\", \"Samedi\", \"Dimanche\"]\n",
    "\n",
    "df_all_weeks = []\n",
    "i = 0\n",
    "while i < len(dataFrame):\n",
    "    this_week = pd.DataFrame()\n",
    "\n",
    "    if dataFrame.iloc[i].Jour == 'Lundi':\n",
    "        today = dataFrame.iloc[i].Date\n",
    "        j = i\n",
    "        while j < len(dataFrame) and dataFrame.iloc[j].Date == today:\n",
    "            #on recupere d'abord tous les 'lundi'\n",
    "            j += 1\n",
    "        for week_day in week_days:\n",
    "            while j < len(dataFrame) and dataFrame.iloc[j].Jour == week_day:\n",
    "                j+=1\n",
    "        this_week = dataFrame.iloc[i:j]\n",
    "        df_all_weeks.append(this_week)\n",
    "        i = j\n",
    "    else:\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff1a25bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moyenneSemaine(week):\n",
    "    return np.mean(list(week.Last))\n",
    "    \n",
    "def moyenneMobileSemaine(num_semaine, profondeur):\n",
    "    liste = []\n",
    "    k = num_semaine\n",
    "    \n",
    "    while k >= 0 and len(liste) < profondeur:\n",
    "        week = df_all_weeks[k]\n",
    "        liste.append(moyenneSemaine(week))\n",
    "        k -= 1\n",
    "        \n",
    "    return np.mean(liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4a93ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chercher_semaine_donnees_brutes(date, time):\n",
    "    if time == 'Semaine':\n",
    "        time = ' 08:00:00.0'\n",
    "    day, month, year = date.split(\"/\")\n",
    "    \n",
    "    for nb_week in range(len(df_all_weeks)):\n",
    "        df = df_all_weeks[nb_week]\n",
    "        firstDate = df.iloc[0].Date\n",
    "        lastDate = df.iloc[len(df)-1].Date\n",
    "        #print(\"fD \" + firstDate + \", lD \" + lastDate)\n",
    "        if firstDate.split(\"/\")[2] == year or lastDate.split(\"/\")[2] == year:\n",
    "            #if not then we keep going with the next week\n",
    "            # we do so, so as to greatly reduce the amount of dataframes to look into to find the right one\n",
    "            i = 0\n",
    "            while i < len(df) and not (df.iloc[i].Date == date and df.iloc[i].Time == time):\n",
    "                i += 1\n",
    "            if i < len(df):\n",
    "                #we have found the right week\n",
    "                return nb_week, i\n",
    "                \n",
    "    return -1, -1 #no matching result has been found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2259bd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverseNormalizationColumn(df, df_normalise, date, time, donnee, profondeur):\n",
    "    \n",
    "    nb_week, iloc = chercher_semaine_donnees_brutes(date, time)\n",
    "    nb_week -= 1 #using week n to normalize the week intersting us, week n+1\n",
    "    if (nb_week < 0):\n",
    "        return -1\n",
    "    else:\n",
    "        df_norm = df_normalise.copy(deep=True)\n",
    "        if time == 'Semaine': #goal is to create a fake 'Time' column for daily dataFrames, where such column isn't present\n",
    "            time = ' 08:00:00.0'\n",
    "        \n",
    "        current_week = df_all_weeks[nb_week]\n",
    "        our_week = df_all_weeks[nb_week+1]\n",
    "        \n",
    "        coeff = moyenneMobileSemaine(nb_week, profondeur)\n",
    "\n",
    "        if donnee == 'Last':\n",
    "            normValue = list(df_norm.loc[(df_norm.Date == date) & (df_norm.Time == time)].Last)[0]\n",
    "        elif donnee == 'Open':\n",
    "            normValue = list(df_norm.loc[(df_norm.Date == date) & (df_norm.Time == time)].Open)[0]\n",
    "        elif donnee == 'High':\n",
    "            normValue = list(df_norm.loc[(df_norm.Date == date) & (df_norm.Time == time)].High)[0]\n",
    "        else:\n",
    "            normValue = list(df_norm.loc[(df_norm.Date == date) & (df_norm.Time == time)].Low)[0]  \n",
    "        \n",
    "        unNormalizedValue = coeff*normValue\n",
    "        return unNormalizedValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "632496f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverseNormalizationColumn(df, df_normalise, date, time, donnee, profondeur):\n",
    "    \n",
    "    nb_week, iloc = chercher_semaine_donnees_brutes(date, time)\n",
    "    nb_week -= 1 #using week n to normalize the week intersting us, week n+1\n",
    "    if (nb_week < 0):\n",
    "        return -1\n",
    "    else:\n",
    "        df_norm = df_normalise.copy(deep=True)\n",
    "        if time == 'Semaine': #goal is to create a fake 'Time' column for daily dataFrames, where such column isn't present\n",
    "            time = '08:00:00'\n",
    "            times = ['08:00:00']*len(df_norm)\n",
    "            df_norm.insert(loc=len(df_norm.columns), column='Time', value=pd.Series(times))\n",
    "        \n",
    "        current_week = df_all_weeks[nb_week]\n",
    "        our_week = df_all_weeks[nb_week+1]\n",
    "        \n",
    "        coeff = moyenneMobileSemaine(nb_week, profondeur)\n",
    "\n",
    "        if donnee == 'Last':\n",
    "            normValue = list(df_norm.loc[(df_norm.Date == date) & (df_norm.Time == time)].Last)[0]\n",
    "        elif donnee == 'Open':\n",
    "            normValue = list(df_norm.loc[(df_norm.Date == date) & (df_norm.Time == time)].Open)[0]\n",
    "        elif donnee == 'High':\n",
    "            normValue = list(df_norm.loc[(df_norm.Date == date) & (df_norm.Time == time)].High)[0]\n",
    "        else:\n",
    "            normValue = list(df_norm.loc[(df_norm.Date == date) & (df_norm.Time == time)].Low)[0]  \n",
    "        \n",
    "        unNormalizedValue = coeff*normValue\n",
    "        return unNormalizedValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9965b3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverseNormalization(dataFrame_donnees_brutes, dataFrame_normalise, date, time, profondeur):\n",
    "    reverseNormOpen = reverseNormalizationColumn(dataFrame_donnees_brutes, dataFrame_normalise, date, time, 'Open', profondeur)\n",
    "    reverseNormHigh = reverseNormalizationColumn(dataFrame_donnees_brutes, dataFrame_normalise, date, time, 'High', profondeur)\n",
    "    reverseNormLow = reverseNormalizationColumn(dataFrame_donnees_brutes, dataFrame_normalise, date, time, 'Low', profondeur)\n",
    "    reverseNormLast = reverseNormalizationColumn(dataFrame_donnees_brutes, dataFrame_normalise, date, time, 'Last', profondeur)\n",
    "    \n",
    "    return round(reverseNormOpen, 0), round(reverseNormHigh, 0), round(reverseNormLow, 0), round(reverseNormLast, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b318cd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverseDaily(dataFrame_daily, dataFrame_norm_daily, profondeur):    \n",
    "    dates = []\n",
    "    opens = []\n",
    "    highs = []\n",
    "    lows = []\n",
    "    lasts = []\n",
    "\n",
    "    for i in range(len(dataFrame_norm_daily)):\n",
    "        tmp_df = dataFrame_norm_daily.iloc[i]\n",
    "        date = tmp_df.Date\n",
    "        open_, high, low, last = reverseNormalization(dataFrame_daily, dataFrame_norm_daily, date, 'Semaine', profondeur)\n",
    "        dates.append(date)\n",
    "        opens.append(open_)\n",
    "        highs.append(high)\n",
    "        lows.append(low)\n",
    "        lasts.append(last)\n",
    "        \n",
    "    df_reversedNorm_day = pd.DataFrame()\n",
    "    df_reversedNorm_day.insert(loc=0, column='Date', value=pd.Series(dates))\n",
    "    df_reversedNorm_day.insert(loc=1, column='Open', value=pd.Series(opens))\n",
    "    df_reversedNorm_day.insert(loc=2, column='High', value=pd.Series(highs))\n",
    "    df_reversedNorm_day.insert(loc=3, column='Low', value=pd.Series(lows))\n",
    "    df_reversedNorm_day.insert(loc=4, column='Last', value=pd.Series(lasts))\n",
    "        \n",
    "    df_reversed_day = df_reversedNorm_day.loc[df_reversedNorm_day.High != -1]\n",
    "    return df_reversed_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc77d15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverseInitialBalance(dataFrame_IB, dataFrame_norm_IB, profondeur):    \n",
    "    dates = []\n",
    "    opens = []\n",
    "    highs = []\n",
    "    lows = []\n",
    "    lasts = []\n",
    "    \n",
    "    df_norm_IB = dataFrame_norm_IB.copy(deep=True)\n",
    "    df_norm_IB = df_norm_IB.rename(columns={'Open Matinal': 'Open'})\n",
    "    df_norm_IB = df_norm_IB.rename(columns={'High Matinal': 'High'})\n",
    "    df_norm_IB = df_norm_IB.rename(columns={'Low Matinal': 'Low'})\n",
    "    df_norm_IB = df_norm_IB.rename(columns={'Last Matinal': 'Last'})\n",
    "    \n",
    "    for i in range(len(dataFrame_norm_IB)):\n",
    "        tmp_df = df_norm_IB.iloc[i]\n",
    "        date = tmp_df.Date\n",
    "        open_, high, low, last = reverseNormalization(dataFrame_IB, df_norm_IB, date, 'Semaine', profondeur)\n",
    "        dates.append(date)\n",
    "        opens.append(open_)\n",
    "        highs.append(high)\n",
    "        lows.append(low)\n",
    "        lasts.append(last)\n",
    "        \n",
    "    df_reversedNorm_day = pd.DataFrame()\n",
    "    df_reversedNorm_day.insert(loc=0, column='Date', value=pd.Series(dates))\n",
    "    df_reversedNorm_day.insert(loc=1, column='Open', value=pd.Series(opens))\n",
    "    df_reversedNorm_day.insert(loc=2, column='High', value=pd.Series(highs))\n",
    "    df_reversedNorm_day.insert(loc=3, column='Low', value=pd.Series(lows))\n",
    "    df_reversedNorm_day.insert(loc=4, column='Close', value=pd.Series(lasts))\n",
    "        \n",
    "    df_reversed_day = df_reversedNorm_day.loc[df_reversedNorm_day.High != -1]\n",
    "    return df_reversed_day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2056fc88",
   "metadata": {},
   "source": [
    "# De-Normaliser : Mois par Mois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0098cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moyennes_last_list(df_daily):\n",
    "    \"\"\"\n",
    "    calcule les moyennes du last mois par mois\n",
    "    \"\"\"\n",
    "    actual_month = 1\n",
    "    moyenne_last = 0\n",
    "    moyenne_last_list = []\n",
    "    nb_days_month = 0\n",
    "    for k in range(len(df_daily)):\n",
    "        if(df_daily['Date'][k].split('/')[1]==str(actual_month)):\n",
    "            moyenne_last += df_daily['Last'][k]\n",
    "            nb_days_month +=1\n",
    "        else:\n",
    "            moyenne_last /= nb_days_month\n",
    "            moyenne_last_list.append(moyenne_last)\n",
    "            actual_month += 1\n",
    "            if (actual_month == 13):\n",
    "                actual_month = 1\n",
    "            moyenne_last = df_daily['Last'][k]\n",
    "            nb_days_month =1\n",
    "    return moyenne_last_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daad9db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moyennes_volumes_month(df_daily):\n",
    "    \"\"\"\n",
    "    calcule la moyenne du volume, du bidVolume et de l'askVolume sur toute la période\n",
    "    \"\"\"\n",
    "    moyenne_BidVol = np.sum(list(df_daily.BidVolume)) / len(df_daily.BidVolume)\n",
    "    moyenne_AskVol = np.sum(list(df_daily.AskVolume)) / len(df_daily.AskVolume)\n",
    "    moyenne_Vol = np.sum(list(df_daily.Volume)) / len(df_daily.Volume)\n",
    "    BidVolume = []\n",
    "    AskVolume = []\n",
    "    Volume = []\n",
    "    for k in range(22, len(df_daily)):\n",
    "        BidVolume.append(df_daily.BidVolume[k]/moyenne_BidVol)\n",
    "        AskVolume.append(df_daily.AskVolume[k]/moyenne_AskVol)\n",
    "        Volume.append(df_daily.Volume[k]/moyenne_Vol)\n",
    "    return moyenne_BidVol, moyenne_AskVol, moyenne_Vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a41b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm_month(df_daily, df_normalized, moyenne_last_list, moyenne_BidVol, moyenne_AskVol, moyenne_Vol):\n",
    "    \"effectue la dénormalisation mois par mois\"\n",
    "    Open = []\n",
    "    High = []\n",
    "    Low = []\n",
    "    Last = []\n",
    "    actual_month = 2\n",
    "    index_mean_precedent_month = 0\n",
    "    for k in range(len(df_normalized)):\n",
    "        if(df_normalized['Date'][k].split('/')[1]==str(actual_month)):\n",
    "            Open.append(df_normalized['Open'][k]*moyenne_last_list[index_mean_precedent_month])\n",
    "            High.append(df_normalized['High'][k]*moyenne_last_list[index_mean_precedent_month])\n",
    "            Low.append(df_normalized['Low'][k]*moyenne_last_list[index_mean_precedent_month])\n",
    "            Last.append(df_normalized['Last'][k]*moyenne_last_list[index_mean_precedent_month])\n",
    "        else:\n",
    "            actual_month += 1\n",
    "            if (actual_month == 13):\n",
    "                actual_month = 1\n",
    "            index_mean_precedent_month += 1\n",
    "            Open.append(df_normalized['Open'][k]*moyenne_last_list[index_mean_precedent_month])\n",
    "            High.append(df_normalized['High'][k]*moyenne_last_list[index_mean_precedent_month])\n",
    "            Low.append(df_normalized['Low'][k]*moyenne_last_list[index_mean_precedent_month])\n",
    "            Last.append(df_normalized['Last'][k]*moyenne_last_list[index_mean_precedent_month])\n",
    "            \n",
    "    BidVolume = []\n",
    "    AskVolume = []\n",
    "    Volume = []\n",
    "    for k in range(len(df_normalized)):\n",
    "        BidVolume.append(df_normalized.BidVolume[k]*moyenne_BidVol)\n",
    "        AskVolume.append(df_normalized.AskVolume[k]*moyenne_AskVol)\n",
    "        Volume.append(df_normalized.Volume[k]*moyenne_Vol)\n",
    "        \n",
    "    denorm_month_dataFrame = pd.DataFrame()\n",
    "    denorm_month_dataFrame['Date'] = df_normalized['Date']\n",
    "    denorm_month_dataFrame['Jour'] = df_normalized['Jour']\n",
    "    denorm_month_dataFrame['Open'] = pd.Series(Open)\n",
    "    denorm_month_dataFrame['High'] = pd.Series(High)\n",
    "    denorm_month_dataFrame['Low'] = pd.Series(Low)\n",
    "    denorm_month_dataFrame['Last'] = pd.Series(Last)\n",
    "    denorm_month_dataFrame['Spread'] = pd.Series(High)-pd.Series(Low)\n",
    "    denorm_month_dataFrame['Volume'] = pd.Series(Volume)\n",
    "    denorm_month_dataFrame['BidVolume'] = pd.Series(BidVolume)\n",
    "    denorm_month_dataFrame['AskVolume'] = pd.Series(AskVolume)\n",
    "    df2 = df_daily.loc[:21,['Date', 'Jour', 'Open', 'High', 'Low', 'Last','Spread','Volume', 'BidVolume','AskVolume' ]]\n",
    "    df3 = pd.concat([df2, denorm_month_dataFrame], ignore_index =True)\n",
    "    return df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bf0f35",
   "metadata": {},
   "source": [
    "# De-Normaliser Max-Min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fd11ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max(df_daily):\n",
    "    max_high = max(df_daily['High'])\n",
    "    min_low = min(df_daily['Low'])\n",
    "    return max_high, min_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2fb151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalisation_min_max(df_daily, norm_min_max_dataFrame, max_high, min_low, moyenne_BidVol, moyenne_AskVol, moyenne_Vol):\n",
    "    denorm_low_min_max = norm_min_max_dataFrame['Low']*(max_high-min_low)+min_low\n",
    "    denorm_high_min_max = norm_min_max_dataFrame['High']*(max_high-min_low)+min_low\n",
    "    denorm_open_min_max = norm_min_max_dataFrame['Open']*(max_high-min_low)+min_low\n",
    "    denorm_close_min_max = norm_min_max_dataFrame['Last']*(max_high-min_low)+min_low\n",
    "    denorm_min_max_dataFrame = pd.DataFrame()\n",
    "    denorm_min_max_dataFrame['Date'] = norm_min_max_dataFrame['Date']\n",
    "    denorm_min_max_dataFrame['Jour'] = norm_min_max_dataFrame['Jour']\n",
    "\n",
    "    denorm_min_max_dataFrame['Open'] = denorm_open_min_max\n",
    "    denorm_min_max_dataFrame['High'] = denorm_high_min_max\n",
    "    denorm_min_max_dataFrame['Low'] = denorm_low_min_max\n",
    "    denorm_min_max_dataFrame['Last'] = denorm_close_min_max\n",
    "    denorm_min_max_dataFrame['Spread'] = denorm_min_max_dataFrame['High']- denorm_min_max_dataFrame['Low']\n",
    "    BidVolume = []\n",
    "    AskVolume = []\n",
    "    Volume = []\n",
    "    for k in range(len(df_daily)):\n",
    "        BidVolume.append(norm_min_max_dataFrame.BidVolume[k]*moyenne_BidVol)\n",
    "        AskVolume.append(norm_min_max_dataFrame.AskVolume[k]*moyenne_AskVol)\n",
    "        Volume.append(norm_min_max_dataFrame.Volume[k]*moyenne_Vol)\n",
    "    denorm_min_max_dataFrame['Volume'] = pd.Series(Volume)\n",
    "    denorm_min_max_dataFrame['BidVolume'] = pd.Series(BidVolume)\n",
    "    denorm_min_max_dataFrame['AskVolume'] = pd.Series(AskVolume)\n",
    "    return denorm_min_max_dataFrame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
